{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19c87e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t = 0.017000s (4%)"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 269\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# Simulate the network\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m t \u001b[38;5;241m<\u001b[39m t0\u001b[38;5;241m+\u001b[39msimtime:\n\u001b[1;32m--> 269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m-\u001b[39mt0 \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;241m*\u001b[39mframeCount \u001b[38;5;129;01mand\u001b[39;00m frameCount \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mvid\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m):\n\u001b[0;32m    270\u001b[0m         stimuli \u001b[38;5;241m=\u001b[39m vid[frameCount][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    271\u001b[0m         set_input_frequencies(neurons, stimuli)\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from __future__ import print_function   # Python 2.X support for print function, not needed in Python 3.X\n",
    "from IPython.display import clear_output\n",
    "#from IPython.core.debugger import set_trace # Activates debugging features\n",
    "\n",
    "def rasterplot(ax, x, y, x_label, y_label):\n",
    "# Function used to plot spike times\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.scatter(x, y, marker='|')\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "\n",
    "def lif_neuron(I_inject, E_L=-65e-3, u_reset=-65e-3, u_thres=-50e-3, R=90e6, tau_m=30e-3):\n",
    "    # LIF neuron with a constant injection current\n",
    "    return {\n",
    "        'type'    : 'lif',\n",
    "        'u'       : u_reset,                   # Membrane potential [Volt]\n",
    "        'E_L'     : E_L,                       # Leakage resting potential [Volt]\n",
    "        'u_reset' : u_reset,                   # Reset potential after spike [Volt]\n",
    "        'u_thres' : u_thres,                   # Threshold for spike generation [Volt]\n",
    "        'R'       : R,                         # Membrane resistance [Ohm]\n",
    "        'tau_m'   : tau_m,                     # Membrane time constant [second]\n",
    "        'I_inj'   : I_inject,                  # Injection current [Ampere]\n",
    "    }\n",
    "\n",
    "def lif_syn_neuron(num_synapses, E_L=-65e-3, u_reset=-65e-3, u_thres=-50e-3, R=90e6, tau_m=30e-3, I_inject=0, tau_syn=50e-3):\n",
    "    # LIF neuron with dynamic synapses\n",
    "    n = lif_neuron(I_inject, E_L, u_reset, u_thres, R, tau_m)\n",
    "    n['tau_syn'] = tau_syn                     # Synapse time constant [second] (can also be an array)\n",
    "    n['I_syn']   = np.zeros(num_synapses)      # Postsynaptic currents [Ampere]\n",
    "    n['w_syn']   = np.zeros(num_synapses)      # Synaptic weights [Ampere]\n",
    "    n['type']    = 'lif_syn'\n",
    "    return n\n",
    "\n",
    "def lif_stdp_neuron(num_synapses, E_L=-65e-3, u_reset=-65e-3, u_thres=-50e-3, R=90e6, tau_m=30e-3, I_inject=0,\n",
    "                    tau_syn=50e-3, tau_pls=20e-3, tau_mns=20e-3, w_max=1e-9, w_min=1e-12, gamma=1):\n",
    "    # LIF neuron with dynamic synapses and pair-based STDP\n",
    "    n = lif_syn_neuron(num_synapses, E_L, u_reset, u_thres, R, tau_m, I_inject, tau_syn)\n",
    "    n['x_pre']   = np.zeros(num_synapses)      # STDP trace of presynaptic spikes\n",
    "    n['y_pst']   = 0                           # STDP trace of postsynaptic spikes (scalar, one neuron)\n",
    "    n['tau_pls'] = tau_pls                     # STDP trace time constant [second] (can also be an array)\n",
    "    n['tau_mns'] = tau_mns                     # STDP trace time constant [second] (can also be an array)\n",
    "    n['w_max']   = w_max                       # Largest allowed value of synapse conductance\n",
    "    n['w_min']   = w_min                       # Lowest allowed value of synapse conductance\n",
    "    n['gamma']   = gamma                       # Learning rate parameter with soft bounds (w_min,w_max)\n",
    "    n['type']    = 'lif_stdp'\n",
    "    return n\n",
    "\n",
    "def integrate(dt, t, neurons):\n",
    "    # Integrate the membrane potential, postsynaptic currents etc one timestep dt\n",
    "    for n in neurons:\n",
    "        if n['type'] == 'lif':\n",
    "            # Integrate membrane potential\n",
    "            dudt = (n['E_L'] - n['u'] + n['R']*n['I_inj']) / n['tau_m']\n",
    "            n['u'] += dt*dudt\n",
    "        elif n['type'] in ['lif_syn','lif_stdp']:\n",
    "            # Integrate array of postsynaptic currents, one current for each synapse\n",
    "            didt = np.divide(-n['I_syn'], n['tau_syn'])\n",
    "            n['I_syn'] += dt*didt\n",
    "            # Integrate membrane potential\n",
    "            dudt = (n['E_L'] - n['u'] + n['R']*(n['I_inj']+sum(n['I_syn']))) / n['tau_m']\n",
    "            n['u'] += dt*dudt\n",
    "            # Integrate local traces for pair-based plasticity\n",
    "            if n['type'] == 'lif_stdp':\n",
    "                n['x_pre'] -= dt*np.divide(n['x_pre'], n['tau_pls'])       # Eq 19.12\n",
    "                n['y_pst'] -= dt*np.divide(n['y_pst'], n['tau_mns'])       # Eq 19.13\n",
    "            \n",
    "def spikegen(dt, t, neurons):\n",
    "    # Implements the non-linear spike generation mechanism\n",
    "    spikes = []\n",
    "    for i,n in enumerate(neurons):\n",
    "        if n['type'] in ['lif','lif_syn','lif_stdp']:\n",
    "            if n['u'] > n['u_thres']:\n",
    "                n['u'] = n['u_reset']\n",
    "                spikes.append(i)\n",
    "        elif n['type'] == 'poisson':\n",
    "            if np.random.rand() < dt*n['frequency']:\n",
    "                spikes.append(i)\n",
    "        elif n['type'] == 'generator':\n",
    "            j = np.searchsorted(n['spike_t'], t, side='right')\n",
    "            if j>0 and t-n['spike_t'][j-1]<dt:\n",
    "                spikes.append(i)\n",
    "                \n",
    "    return spikes\n",
    "\n",
    "def update(dt, t, neurons, connections):\n",
    "    # Update the state of a spiking neural network.\n",
    "    # Refer to Exercise 3 for a reminder about how to set up connections between neurons.\n",
    "    integrate(dt, t, neurons)\n",
    "    spikes = spikegen(dt, t, neurons)\n",
    "\n",
    "    # Update weights and STDP trace for each postsynaptic spike\n",
    "    for spike in spikes:\n",
    "        n = neurons[spike]\n",
    "        if n['type'] in ['lif_stdp']:\n",
    "            n['y_pst'] += 1                                         # Eq 19.13\n",
    "            for i,w in enumerate(n['w_syn']):\n",
    "                if w > 0:                                           # Excitatory synapses\n",
    "                    Aplus = n['gamma']*(n['w_max'] - n['w_syn'][i]) # Eq 19.4\n",
    "                    n['w_syn'][i] += dt*Aplus*n['x_pre'][i]         # Eq 19.14\n",
    "    \n",
    "    # Update synapse currents, weights and STDP traces for each presynaptic spike\n",
    "    for (post, syn, pre) in connections:\n",
    "        for spike in spikes:\n",
    "            if spike == pre:\n",
    "                n = neurons[post]\n",
    "                \n",
    "                if n['type'] not in ['lif_syn', 'lif_stdp']:\n",
    "                    print('Error: Spike sent to neuron type without synapses')\n",
    "                \n",
    "                # Update synapse currents\n",
    "                if n['type'] in ['lif_syn','lif_stdp']:\n",
    "                    n['I_syn'][syn] += n['w_syn'][syn]\n",
    "                    \n",
    "                # Update STDP trace and weight\n",
    "                if n['type'] in ['lif_stdp']:\n",
    "                    n['x_pre'][syn] += 1                                   # Eq 19.12\n",
    "                    if n['w_syn'][syn] > 0:                                # Excitatory synapses\n",
    "                        Aminus = n['gamma']*(n['w_min'] - n['w_syn'][syn]) # Eq 19.4\n",
    "                        n['w_syn'][syn] += dt*Aminus*n['y_pst']            # Eq 19.14\n",
    "    \n",
    "    return spikes\n",
    "\n",
    "def set_input_frequencies(neurons, image):\n",
    "# Convert pixel intensities to spikerates of random (Poisson) neurons\n",
    "    for i in range(N_pixls):\n",
    "        for j in range(N_pixls):\n",
    "            neurons[i*N_pixls+j]['frequency'] = 5 + 55*image[i][j] # 5-60 Hz\n",
    "\n",
    "def reset_input_frequencies(neurons):\n",
    "# Reset frequencies of input neurons to 0 Hz\n",
    "    for i in range(N_pixls):\n",
    "        for j in range(N_pixls):\n",
    "            neurons[i*N_pixls+j]['frequency'] = 0\n",
    "            \n",
    "def plot_digit(plt, data):\n",
    "# Display MNIST images\n",
    "    data = data.view(28,28)\n",
    "    plt.imshow(data, cmap='gray')\n",
    "\n",
    "    \n",
    "def spikerate_filter(spikerate, spikecount, simtime, alpha):\n",
    "# Low-pass filter for estimation of spikerate\n",
    "    if spikerate > 0:\n",
    "        spikerate = alpha*spikerate + (1-alpha)*spikecount/simtime\n",
    "    else:\n",
    "        spikerate = spikecount/simtime\n",
    "    return spikerate\n",
    "\n",
    "def plot_neuron_weights(n):\n",
    "# Plot the input weights of an excitatory neuron (with STDP synapses)\n",
    "    plt.rcParams['figure.figsize'] = [10, 3]\n",
    "    fig,(ax1,ax2) = plt.subplots(1,2)\n",
    "    img = np.zeros((N_pixls,N_pixls))\n",
    "    for i in range(N_pixls):\n",
    "        for j in range(N_pixls):\n",
    "            img[i][j] = n['w_syn'][i*N_pixls+j]/1e-12\n",
    "    ax1.imshow(img, cmap='viridis')\n",
    "    ax2.hist(np.hstack(img))\n",
    "    ax2.set_xlabel('Weight [pA]')\n",
    "    ax2.set_ylabel('No. synapses')\n",
    "    plt.show()\n",
    "\n",
    "# Extract 10 training samples for two classes of digits\n",
    "\n",
    "rightVid = loadDataset(\"right\")\n",
    "leftVid = loadDataset(\"left\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def poisson_neuron(spike_frequency):\n",
    "    # Random spike generator with Poisson distributed spike time intervals, see Section 7.2.1 in the book\n",
    "    return {\n",
    "        'type'      : 'poisson',\n",
    "        'frequency' : spike_frequency          # Average spiking frequency\n",
    "    }\n",
    "\n",
    "N_pixls = 28\n",
    "N_input = N_pixls*N_pixls\n",
    "\n",
    "neurons = []\n",
    "connections = []\n",
    "\n",
    "# Create input neurons, frequencies will be set later\n",
    "for i in range(N_input):\n",
    "    neurons.append(poisson_neuron(0))\n",
    "    \n",
    "# Create two excitatory neurons\n",
    "e1 = lif_stdp_neuron(N_input+1, w_min=0, w_max=10e-12)\n",
    "e2 = lif_stdp_neuron(N_input+1, w_min=0, w_max=10e-12)\n",
    "neurons.append(e1)\n",
    "neurons.append(e2)\n",
    "I_e1 = N_input\n",
    "I_e2 = N_input+1\n",
    "\n",
    "# Define excitatory STDP synapses for the inputs\n",
    "for j in range(N_input):\n",
    "    e1['w_syn'][j] = 2e-12*(0.1 + 0.9*np.random.rand())\n",
    "    e2['w_syn'][j] = 2e-12*(0.1 + 0.9*np.random.rand())\n",
    "    connections.append([I_e1,j,j]) # [post,syn,pre], see Exercise 3 for details\n",
    "    connections.append([I_e2,j,j]) # [post,syn,pre]\n",
    "\n",
    "# Lateral inhibition (neglecting Dale's law to simplify the exercise)\n",
    "I_inhib = N_input\n",
    "e1['w_syn'][I_inhib] = -1e-12\n",
    "e2['w_syn'][I_inhib] = -1e-12\n",
    "connections.append([I_e1,I_inhib,I_e2])\n",
    "connections.append([I_e2,I_inhib,I_e1])\n",
    "\n",
    "# Reset the simulation time\n",
    "t = 0\n",
    "dt = 5e-4\n",
    "simtime = 0.267\n",
    "rsttime = 0.15\n",
    "\n",
    "# Reset spikerate variables\n",
    "e1_spikerate = -1\n",
    "e2_spikerate = -1\n",
    "\n",
    "# Speed up learning a bit\n",
    "e1['gamma'] = 5\n",
    "e2['gamma'] = 5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for iterations in range(50): # Training iterations\n",
    "\n",
    "    # Start time\n",
    "    t0 = t\n",
    "    \n",
    "    # Spike counts of e1 and e2\n",
    "    e1_count = 0\n",
    "    e2_count = 0\n",
    "    \n",
    "    # Sample a different digit every second iteration\n",
    "    stimuli = []\n",
    "    if iterations % 2 == 0:\n",
    "        \n",
    "        vid = rightVid[int(len(rightVid)*np.random.rand())]\n",
    "        ##############################################################################\n",
    "        #INSERT SUPERVISION SIGNAL HERE, INHIBIT ONE OF THE TWO STDP NEURONS\n",
    "        e1['w_syn'][I_inhib] = -200e-12\n",
    "        e2['w_syn'][I_inhib] = 0\n",
    "        ##############################################################################\n",
    "    else:\n",
    "        vid = leftVid[int(len(rightVid)*np.random.rand())]\n",
    "        ##############################################################################\n",
    "        # INSERT SUPERVISION SIGNAL HERE, INHIBIT ONE OF THE TWO STDP NEURONS\n",
    "        e1['w_syn'][I_inhib] = 0\n",
    "        e2['w_syn'][I_inhib] = -300e-12\n",
    "        ##############################################################################\n",
    "    \n",
    "    stimuli = vid[0][0]\n",
    "    frameCount = 1\n",
    "    set_input_frequencies(neurons, stimuli)\n",
    "    \n",
    "    # Simulate the network\n",
    "    while t < t0+simtime:\n",
    "        \n",
    "        if t-t0 > 1/60*frameCount and frameCount != len(vid+1):\n",
    "            stimuli = vid[frameCount][0]\n",
    "            set_input_frequencies(neurons, stimuli)\n",
    "            frameCount += 1\n",
    "        \n",
    "        \n",
    "        # Update network, including STDP\n",
    "        spikes = update(dt, t, neurons, connections)\n",
    "        \n",
    "        # Count number of spikes from e1 and e2\n",
    "        e1_count += spikes.count(I_e1)\n",
    "        e2_count += spikes.count(I_e2)\n",
    "        \n",
    "        # Timestep completed\n",
    "        t += dt\n",
    "        print('\\r t = %fs (%d%%)' % (t, 100*(t-t0)/(simtime+rsttime)), end='')\n",
    "\n",
    "    # Let neurons and synapses rest before the next stimuli \n",
    "    reset_input_frequencies(neurons)\n",
    "    while t < t0+simtime+rsttime:\n",
    "        spikes = update(dt, t, neurons, connections)\n",
    "        e1_count += spikes.count(I_e1)\n",
    "        e2_count += spikes.count(I_e2)\n",
    "        t += dt\n",
    "        print('\\r t = %fs (%d%%)' % (t, 100*(t-t0)/(simtime+rsttime)), end='')\n",
    "\n",
    "    # Refresh the plots\n",
    "    clear_output()\n",
    "    print('\\nStimuli:')\n",
    "    plot_digit(plt,stimuli)\n",
    "    plt.show()\n",
    "    print('Excitatory cell e1 spike count: %d, and weight distribution after %d seconds:' % (e1_count,t))\n",
    "    plot_neuron_weights(e1)\n",
    "    print('Excitatory cell e2 spike count: %d, and weight distribution after %d seconds:' % (e2_count,t))\n",
    "    plot_neuron_weights(e2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0fd972f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "          0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "          1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
      "          1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "    \n",
    "def getData(file):\n",
    "    f = open(file, \"r\")\n",
    "    fileContent = f.readlines()\n",
    "    data = []\n",
    "    for frame in fileContent:\n",
    "        newFrame = frame.replace(\"\\n\",\"\")\n",
    "        newFrame = newFrame.split(\",\")\n",
    "        newFrame = [int(i) for i in newFrame]\n",
    "        newFrame = listToTensor(newFrame, 28)\n",
    "        data.append(newFrame)\n",
    "    return data\n",
    "            \n",
    "def loadDataset(dataset):\n",
    "    if dataset.lower() == \"right\":\n",
    "        dir = Path('C:/Users/marcu/Downloads/D7046E_SSN_BETA/data/Right')\n",
    "    elif dataset.lower() == \"left\":\n",
    "        dir = Path('C:/Users/marcu/Downloads/D7046E_SSN_BETA/data/Left')\n",
    "    else:\n",
    "        print(\"no such dataset\")\n",
    "        return;\n",
    "    Data = []\n",
    "    for child in dir.iterdir():\n",
    "        Data.append(getData(child))\n",
    "        \n",
    "    return(Data)\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "def listToTensor(lst, dim):\n",
    "    \n",
    "    chunked_list = [[list(array) for array in np.array_split(np.array(lst), dim)]]\n",
    "    lst = torch.FloatTensor(chunked_list)\n",
    "    return lst\n",
    "    \n",
    "print(loadDataset(\"right\")[0][10])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db708069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "def motion_detector(video_file=0, compress_to_size=(100,100), show_video=False, frame_step=2, max_frames=np.inf, output_file=\"\"):\n",
    "  \n",
    "  frame_count = 0\n",
    "  previous_frame = None\n",
    "  cap = cv2.VideoCapture(video_file)\n",
    "  preprocessed_file = []\n",
    "  \n",
    "  while True:\n",
    "    frame_count += 1\n",
    "\n",
    "    # 1. Load image; convert to RGB\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # If video check when end or ESC is hit\n",
    "    if frame is None or cv2.waitKey(30) == 27 or frame_count > max_frames:\n",
    "      print(frame_count - 1)\n",
    "      cap.release()\n",
    "      \n",
    "      if show_video:\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "      # if a output file is given save the file\n",
    "      if(output_file != \"\"):\n",
    "        f = open(output_file, 'w')\n",
    "        for item in preprocessed_file:\n",
    "            f.write(','.join([str(x) for x in item]) + '\\n')\n",
    "        f.close()\n",
    "\n",
    "      break\n",
    "\n",
    "    frame = np.flip(frame, axis=1)\n",
    "    frame = cv2.resize(frame, compress_to_size)\n",
    "    frame = cv2.cvtColor(src=frame, code=cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    \n",
    "    if ((frame_count % frame_step) == 0):\n",
    "\n",
    "      # 2. Prepare image; grayscale and blur\n",
    "      prepared_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "      prepared_frame = cv2.GaussianBlur(src=prepared_frame, ksize=(5,5), sigmaX=0)\n",
    "      \n",
    "      # 3. Set previous frame and continue if there is None\n",
    "      if (previous_frame is None):\n",
    "        # First frame; there is no previous one yet\n",
    "        previous_frame = prepared_frame\n",
    "        continue\n",
    "      \n",
    "      # calculate difference and update previous frame\n",
    "      diff_frame = cv2.absdiff(src1=previous_frame, src2=prepared_frame)\n",
    "      previous_frame = prepared_frame\n",
    "\n",
    "      # 4. Dilute the image a bit to make differences more seeable; more suitable for contour detection\n",
    "      # kernel = np.ones((5, 5))\n",
    "      # diff_frame = cv2.dilate(diff_frame, kernel, 1)\n",
    "\n",
    "      # 5. Only take different areas that are different enough (>20 / 255)\n",
    "      thresh_frame = cv2.threshold(src=diff_frame, thresh=20, maxval=255, type=cv2.THRESH_BINARY)[1]\n",
    "\n",
    "      # Save every frame\n",
    "      preprocessed_file.append((thresh_frame.flatten()/255).astype(int))\n",
    "\n",
    "      if(show_video):\n",
    "        both_frame = np.concatenate((prepared_frame, thresh_frame), axis=1)\n",
    "        cv2.imshow('webcam', both_frame)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc2ee11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "motion_detector(output_file=\"test\", show_video=True, max_frames=50, compress_to_size=(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2962f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
